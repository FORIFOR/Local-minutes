import { useState, useEffect, useRef } from 'react'
import { useNavigate, useSearchParams } from 'react-router-dom'
import { api } from '../lib/config'

interface LiveTranscript {
  type: 'partial' | 'final'
  text: string
  speaker?: string
  range?: [number, number]
  mt?: string
  id?: number
}

export default function Recording() {
  const navigate = useNavigate()
  const [searchParams] = useSearchParams()
  const eventIdParam = searchParams.get('event_id') || ''
  const [isRecording, setIsRecording] = useState(false)
  const [currentEvent, setCurrentEvent] = useState<any>(null)
  const [audioSource, setAudioSource] = useState('microphone')
  const [transcripts, setTranscripts] = useState<LiveTranscript[]>([])
  const [wsStats, setWsStats] = useState<any>({})
  const [micPermission, setMicPermission] = useState<'unknown' | 'granted' | 'denied'>('unknown')
  const [isCheckingPermission, setIsCheckingPermission] = useState(false)
  const [audioLevel, setAudioLevel] = useState(0)
  const [isSafari, setIsSafari] = useState(false)
  const [isChromeLike, setIsChromeLike] = useState(false) // Chrome/Edge/Chromium ç³»
  const [showScreenTip, setShowScreenTip] = useState(false)
  const noAudioAlertShownRef = useRef(false)
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const wsRef = useRef<WebSocket | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const animationRef = useRef<number | null>(null)
  const transcriptsEndRef = useRef<HTMLDivElement | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const workletNodeRef = useRef<AudioWorkletNode | null>(null)

  useEffect(() => {
    // autostart ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è‡ªå‹•é–‹å§‹
    if (searchParams.get('autostart') === '1') {
      handleStart()
    }

    // ãƒã‚¤ã‚¯æ¨©é™ã®åˆæœŸãƒã‚§ãƒƒã‚¯
    checkMicPermission()
    // ãƒ–ãƒ©ã‚¦ã‚¶åˆ¤å®š
    try {
      const ua = navigator.userAgent
      const isSafariUA = /Safari\//.test(ua) && !/Chrome\//.test(ua) && !/Chromium\//.test(ua)
      const isChromeUA = /Chrome\//.test(ua) || /Chromium\//.test(ua) || /Edg\//.test(ua)
      setIsSafari(isSafariUA)
      setIsChromeLike(isChromeUA)
      // ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã®ãƒ’ãƒ³ãƒˆã¯ Chrome ç³»ã§ screen ã‚’é¸ã‚“ã ã¨ãã«è¡¨ç¤º
      setShowScreenTip(false)
    } catch {}
  }, [searchParams])

  const checkMicPermission = async () => {
    if (!navigator.permissions || audioSource !== 'microphone') {
      setMicPermission('unknown')
      return
    }
    
    setIsCheckingPermission(true)
    try {
      const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName })
      setMicPermission(permission.state === 'granted' ? 'granted' : 
                      permission.state === 'denied' ? 'denied' : 'unknown')
      
      // æ¨©é™çŠ¶æ…‹ã®å¤‰æ›´ã‚’ç›£è¦–
      permission.onchange = () => {
        setMicPermission(permission.state === 'granted' ? 'granted' : 
                        permission.state === 'denied' ? 'denied' : 'unknown')
      }
    } catch (error) {
      console.log('æ¨©é™ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—:', error)
      setMicPermission('unknown')
    } finally {
      setIsCheckingPermission(false)
    }
  }

  // å…¥åŠ›ã‚½ãƒ¼ã‚¹å¤‰æ›´æ™‚ã«ãƒã‚¤ã‚¯æ¨©é™ã‚’å†ãƒã‚§ãƒƒã‚¯
  useEffect(() => {
    checkMicPermission()
    // Chromeç³»ã§ã‚¿ãƒ–éŸ³å£°ã‚’æ¡ˆå†…
    if (audioSource === 'screen' && isChromeLike) {
      setShowScreenTip(true)
    } else {
      setShowScreenTip(false)
    }
  }, [audioSource])

  // æ–‡å­—èµ·ã“ã—çµæœæ›´æ–°æ™‚ã®è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
  useEffect(() => {
    if (transcripts.length > 0) {
      setTimeout(() => {
        transcriptsEndRef.current?.scrollIntoView({ behavior: 'smooth' })
      }, 100)
    }
  }, [transcripts])

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç ´æ£„æ™‚ã‚„ãƒšãƒ¼ã‚¸é›¢è„±æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    const cleanup = () => {
      if (isRecording) {
        console.log('ğŸš¨ ç·Šæ€¥åœæ­¢: ãƒšãƒ¼ã‚¸é›¢è„±ã«ã‚ˆã‚‹ãƒã‚¤ã‚¯åœæ­¢')
        handleStop()
      }
    }

    // ãƒšãƒ¼ã‚¸é›¢è„±æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    window.addEventListener('beforeunload', cleanup)
    
    // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç ´æ£„æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    return () => {
      window.removeEventListener('beforeunload', cleanup)
      cleanup()
    }
  }, [isRecording])

  const startAudioLevelMonitoring = () => {
    const analyser = analyserRef.current
    if (!analyser) return

    const dataArray = new Uint8Array(analyser.frequencyBinCount)
    
    const updateAudioLevel = () => {
      analyser.getByteFrequencyData(dataArray)
      const sum = dataArray.reduce((acc, value) => acc + value, 0)
      const average = sum / dataArray.length
      const normalizedLevel = Math.min(average / 128, 1)
      setAudioLevel(normalizedLevel)
      
      if (analyserRef.current) {
        animationRef.current = requestAnimationFrame(updateAudioLevel)
      }
    }
    
    updateAudioLevel()
  }

  const stopAudioLevelMonitoring = () => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current)
      animationRef.current = null
    }
    setAudioLevel(0)
  }

  const handleStart = async () => {
    try {
      console.log('ğŸ¤ éŒ²éŸ³é–‹å§‹å‡¦ç†é–‹å§‹')
      
      // 1. æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ä½œæˆ
      let event: any
      if (eventIdParam) {
        console.log('ğŸ“ æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆã§éŒ²éŸ³é–‹å§‹:', eventIdParam)
        event = { id: eventIdParam }
      } else {
        console.log('ğŸ“ ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆä¸­...')
        const response = await fetch(api('/api/events'), {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            title: `éŒ²éŸ³ ${new Date().toLocaleString('ja-JP')}`,
            start_ts: Math.floor(Date.now() / 1000),
            lang: 'ja'
          })
        })
        event = await response.json()
        console.log('âœ… ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆå®Œäº†:', event.id)
      }

      // 2. ã‚¤ãƒ™ãƒ³ãƒˆé–‹å§‹ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
      console.log('ğŸ”‘ ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ä¸­...', event.id)
      const startResponse = await fetch(api(`/api/events/${event.id}/start`), { method: 'POST' })
      const { token } = await startResponse.json()
      event.ws_token = token
      console.log('âœ… ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å®Œäº†:', token)

      setCurrentEvent(event)

      // 3. éŸ³å£°å…¥åŠ›å–å¾—
      console.log('ğŸ§ éŸ³å£°å…¥åŠ›å–å¾—ä¸­...', audioSource)
      let stream: MediaStream
      if (audioSource === 'screen') {
        // ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆéŸ³å£°ä»˜ãï¼‰
        // Safari ã¯å¤šãã®ç’°å¢ƒã§éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ãŒä¾›çµ¦ã•ã‚Œãªã„ãŸã‚ã€å®Ÿè³ªãƒã‚¤ã‚¯ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        const displayStream = await navigator.mediaDevices.getDisplayMedia({ 
          video: true,  // videoã¯trueã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹
          audio: {
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false
          }
        })

        // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã®ã¿ã‚’å–å¾—
        const audioTracks = displayStream.getAudioTracks()
        if (audioTracks.length === 0) {
          // éŸ³å£°ãªã—ã®å ´åˆã¯ãƒã‚¤ã‚¯ã¨ä½µç”¨
          console.log('âš ï¸ ç”»é¢ã«éŸ³å£°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¤ã‚¯éŸ³å£°ã¨ä½µç”¨ã—ã¾ã™ã€‚')
          displayStream.getVideoTracks().forEach(track => track.stop())

          // ãƒã‚¤ã‚¯éŸ³å£°ã‚’å–å¾—ã—ã¦ä½¿ç”¨
          stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false
            } 
          })
          if (!noAudioAlertShownRef.current) {
            const msgSafari = 'Safariã§ã¯ç”»é¢å…±æœ‰ã«éŸ³å£°ãŒå«ã¾ã‚Œãªã„ãŸã‚ã€ãƒã‚¤ã‚¯éŸ³å£°ã§éŒ²éŸ³ã—ã¾ã™ã€‚\n\nç”»é¢(ã‚¿ãƒ–)ã®éŸ³å£°ã‚’éŒ²éŸ³ã—ãŸã„å ´åˆã¯ Chrome/Edge ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚'
            const msgChrome = 'é¸æŠã—ãŸç”»é¢ã«éŸ³å£°ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒã‚¤ã‚¯éŸ³å£°ã§éŒ²éŸ³ã—ã¾ã™ã€‚\n\nã‚¿ãƒ–éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ã«ã¯ï¼š\n1. Chrome/Edge ã®ã€Œã‚¿ãƒ–ã€ã‚’é¸æŠ\n2. ã€ŒéŸ³å£°ã‚’å…±æœ‰ã€ã«ãƒã‚§ãƒƒã‚¯\n3. éŸ³å£°ãŒå†ç”Ÿã•ã‚Œã¦ã„ã‚‹ã‚¿ãƒ–ã‚’é¸æŠ'
            alert(isSafari ? msgSafari : msgChrome)
            noAudioAlertShownRef.current = true
          }
        } else {
          // éŸ³å£°ã®ã¿ã®Streamã‚’ä½œæˆ
          stream = new MediaStream(audioTracks)

          // ãƒ“ãƒ‡ã‚ªãƒˆãƒ©ãƒƒã‚¯ã¯åœæ­¢ï¼ˆéŸ³å£°ã®ã¿ä½¿ç”¨ï¼‰
          displayStream.getVideoTracks().forEach(track => track.stop())
          console.log('âœ… ç”»é¢éŸ³å£°ã‚’å–å¾—ã—ã¾ã—ãŸ:', audioTracks.map(t => t.label))
        }
      } else {
        // ãƒã‚¤ã‚¯å…¥åŠ›
        stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false
          } 
        })
      }
      streamRef.current = stream
      console.log('âœ… éŸ³å£°å…¥åŠ›å–å¾—å®Œäº†:', stream.getTracks().map(t => `${t.kind}:${t.label}`))

      // 4. WebSocketæ¥ç¶š
      const wsUrl = api('/ws/stream').replace('http', 'ws') + `?event_id=${event.id}&token=${event.ws_token}`
      console.log('ğŸ”— WebSocketæ¥ç¶šä¸­...', wsUrl)
      const ws = new WebSocket(wsUrl)
      wsRef.current = ws

      ws.onopen = () => {
        console.log('âœ… WebSocketæ¥ç¶šæˆåŠŸ')
      }

      ws.onmessage = (e) => {
        try {
          const data = JSON.parse(e.data)
          console.log('ğŸ“¨ WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡:', data.type, data.text?.substring(0, 50) || data.message)
          
          if (data.type === 'partial' || data.type === 'final') {
            setTranscripts(prev => {
              const newTranscripts = [...prev]
              
              // é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼šåŒã˜ãƒ†ã‚­ã‚¹ãƒˆã¨è¿‘ã„æ™‚é–“ç¯„å›²ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
              const isDuplicate = data.type === 'final' && newTranscripts.some(existing => 
                existing.type === 'final' && 
                existing.text === data.text &&
                existing.range && data.range &&
                Math.abs(existing.range[0] - data.range[0]) < 2.0 // 2ç§’ä»¥å†…ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯
              )
              
              if (isDuplicate) {
                console.log('ğŸ“ é‡è¤‡ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—:', data.text)
                return newTranscripts
              }
              
              if (data.type === 'partial') {
                // éƒ¨åˆ†çµæœ: æœ«å°¾ã®partialã‚’ç½®ãæ›ãˆã€ã¾ãŸã¯æ–°è¦è¿½åŠ 
                if (newTranscripts.length > 0 && newTranscripts[newTranscripts.length - 1].type === 'partial') {
                  newTranscripts[newTranscripts.length - 1] = { ...data, id: Date.now() }
                } else {
                  newTranscripts.push({ ...data, id: Date.now() })
                }
              } else {
                // ç¢ºå®šçµæœ: æœ«å°¾ã®partialã‚’ç½®ãæ›ãˆã‚‹ã‹ã€æ–°è¦è¿½åŠ 
                if (newTranscripts.length > 0 && newTranscripts[newTranscripts.length - 1].type === 'partial') {
                  newTranscripts[newTranscripts.length - 1] = { ...data, id: Date.now() }
                } else {
                  newTranscripts.push({ ...data, id: Date.now() })
                }
              }
              
              return newTranscripts
            })
          } else if (data.type === 'stat') {
            setWsStats(data)
          } else if (data.type === 'warn') {
            console.warn('âš ï¸ ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®è­¦å‘Š:', data.message)
          }
        } catch (error) {
          console.error('âŒ WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è§£æã«å¤±æ•—:', error)
        }
      }

      ws.onerror = (error) => {
        console.error('âŒ WebSocketæ¥ç¶šã‚¨ãƒ©ãƒ¼:', error)
      }

      ws.onclose = (event) => {
        console.log('ğŸ”Œ WebSocketæ¥ç¶šãŒé–‰ã˜ã‚‰ã‚Œã¾ã—ãŸ:', event.code, event.reason)
      }

      // 5. éŸ³å£°éŒ²éŸ³é–‹å§‹
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      mediaRecorderRef.current = mediaRecorder

      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¯ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã§16kHz/monoã«å¤‰æ›ã—ã¦WebSocketã«é€ä¿¡
      const audioContext = new AudioContext()
      audioContextRef.current = audioContext
      const source = audioContext.createMediaStreamSource(stream)
      
      // éŸ³å£°ãƒ¬ãƒ™ãƒ«åˆ†æç”¨ã®AnalyserNode
      const analyser = audioContext.createAnalyser()
      analyser.fftSize = 256
      analyserRef.current = analyser
      source.connect(analyser)
      
      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–ã‚’é–‹å§‹
      startAudioLevelMonitoring()
      
      await audioContext.audioWorklet.addModule('/worklet.js')
      const workletNode = new AudioWorkletNode(audioContext, 'downsampler')
      workletNodeRef.current = workletNode
      
      workletNode.port.onmessage = (e) => {
        if (ws.readyState === WebSocket.OPEN && e.data.type === 'chunk') {
          console.log('ğŸµ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡:', e.data.data.byteLength, 'bytes')
          ws.send(e.data.data)
        } else {
          console.warn('âš ï¸ WebSocketæœªæ¥ç¶šã®ãŸã‚éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç ´æ£„:', ws.readyState)
        }
      }

      source.connect(workletNode)
      // workletNode.connect(audioContext.destination) // ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯é˜²æ­¢ã®ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ

      console.log('ğŸ¤ éŒ²éŸ³é–‹å§‹å®Œäº†ï¼')
      setIsRecording(true)

    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error)
      
      let errorMessage = 'éŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'
      
      if (error instanceof DOMException) {
        switch (error.name) {
          case 'NotAllowedError':
            errorMessage += '\n\nãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚\nâ€¢ ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒã‚¤ã‚¯ã‚’è¨±å¯ã—ã¦ãã ã•ã„\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã§ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„'
            break
          case 'NotFoundError':
            errorMessage += '\n\nãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\nâ€¢ ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„\nâ€¢ ä»–ã®ã‚¢ãƒ—ãƒªãŒãƒã‚¤ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„'
            break
          case 'NotSupportedError':
            errorMessage += '\n\nãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¾ãŸã¯ç’°å¢ƒã§ã¯éŸ³å£°éŒ²éŸ³ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'
            break
          case 'NotReadableError':
            errorMessage += '\n\nãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nâ€¢ ä»–ã®ã‚¢ãƒ—ãƒªãŒãƒã‚¤ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„\nâ€¢ ãƒã‚¤ã‚¯ã‚’å†æ¥ç¶šã—ã¦ã¿ã¦ãã ã•ã„'
            break
          case 'OverconstrainedError':
            errorMessage += '\n\næŒ‡å®šã•ã‚ŒãŸéŸ³å£°è¨­å®šãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nâ€¢ åˆ¥ã®å…¥åŠ›ã‚½ãƒ¼ã‚¹ã‚’è©¦ã—ã¦ãã ã•ã„'
            break
          default:
            errorMessage += `\n\nã‚¨ãƒ©ãƒ¼ã®è©³ç´°: ${error.message}`
        }
      } else {
        errorMessage += `\n\nã‚¨ãƒ©ãƒ¼ã®è©³ç´°: ${error}`
      }
      
      alert(errorMessage)
    }
  }

  const handleStop = async () => {
    try {
      console.log('ğŸ›‘ éŒ²éŸ³åœæ­¢å‡¦ç†é–‹å§‹')
      
      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–åœæ­¢
      stopAudioLevelMonitoring()
      analyserRef.current = null
      console.log('âœ… éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–åœæ­¢')

      // WebSocketåˆ‡æ–­
      if (wsRef.current) {
        wsRef.current.close()
        wsRef.current = null
        console.log('âœ… WebSocketåˆ‡æ–­')
      }

      // MediaRecorderåœæ­¢
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop()
        mediaRecorderRef.current = null
        console.log('âœ… MediaRecorderåœæ­¢')
      }

      // AudioWorkletNodeåœæ­¢
      if (workletNodeRef.current) {
        workletNodeRef.current.disconnect()
        workletNodeRef.current = null
        console.log('âœ… AudioWorkletNodeåœæ­¢')
      }

      // AudioContextåœæ­¢
      if (audioContextRef.current) {
        await audioContextRef.current.close()
        audioContextRef.current = null
        console.log('âœ… AudioContextåœæ­¢')
      }

      // éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢ï¼ˆãƒã‚¤ã‚¯ã‚ªãƒ•ï¼‰
      if (streamRef.current) {
        console.log('ğŸ¤ ãƒã‚¤ã‚¯ã‚’ã‚ªãƒ•ã«ã—ã¦ã„ã¾ã™...')
        streamRef.current.getTracks().forEach(track => {
          console.log(`ğŸ“´ éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯åœæ­¢: ${track.kind} (${track.label}) - enabled: ${track.enabled} -> false`)
          track.enabled = false  // ã¾ãšç„¡åŠ¹åŒ–
          track.stop()           // ãã—ã¦åœæ­¢
        })
        streamRef.current = null
        console.log('âœ… ãƒã‚¤ã‚¯åœæ­¢å®Œäº†')
        
        // ãƒã‚¤ã‚¯åœæ­¢å¾Œã®çŠ¶æ…‹ç¢ºèª
        setTimeout(() => {
          if (navigator.mediaDevices && navigator.mediaDevices.enumerateDevices) {
            navigator.mediaDevices.enumerateDevices().then(devices => {
              const audioInputs = devices.filter(device => device.kind === 'audioinput')
              console.log('ğŸ” ãƒã‚¤ã‚¯åœæ­¢å¾Œã®ãƒ‡ãƒã‚¤ã‚¹çŠ¶æ…‹:', audioInputs.map(d => ({
                label: d.label,
                deviceId: d.deviceId.substring(0, 8) + '...'
              })))
            })
          }
        }, 500)
      }

      setIsRecording(false)
      console.log('ğŸ›‘ éŒ²éŸ³åœæ­¢å‡¦ç†å®Œäº†')

      // ã‚¤ãƒ™ãƒ³ãƒˆåœæ­¢APIå‘¼ã³å‡ºã—
      if (currentEvent) {
        await fetch(api(`/api/events/${currentEvent.id}/stop`), {
          method: 'POST'
        })
        
        // ä¼šè­°è©³ç´°ãƒšãƒ¼ã‚¸ã«é·ç§»
        navigate(`/meetings/${currentEvent.id}`)
      }

    } catch (error) {
      console.error('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼:', error)
    }
  }

  const getSourceLabel = () => {
    switch (audioSource) {
      case 'microphone': return 'ãƒã‚¤ã‚¯'
      case 'blackhole': return 'ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ï¼ˆBlackHoleç­‰ï¼‰'
      case 'screen': return 'ã‚¿ãƒ–ã®éŸ³å£°ï¼ˆç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼‰'
      default: return 'ãƒã‚¤ã‚¯'
    }
  }

  return (
    <div className="max-w-4xl mx-auto space-y-6">
      {/* éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« */}
      <div className="text-center space-y-4">
        <h1 className="text-2xl font-bold text-gray-900">éŒ²éŸ³</h1>
        
        {/* å…¥åŠ›ã‚½ãƒ¼ã‚¹é¸æŠ */}
        <div className="flex justify-center items-center gap-4">
          <select
            value={audioSource}
            onChange={(e) => setAudioSource(e.target.value)}
            disabled={isRecording}
            className="px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
          >
            <option value="microphone">ãƒã‚¤ã‚¯</option>
            <option value="blackhole">ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ï¼ˆBlackHoleç­‰ï¼‰</option>
            {isSafari ? (
              <option value="screen" disabled>ã‚¿ãƒ–ã®éŸ³å£°ï¼ˆSafariã¯éå¯¾å¿œï¼‰</option>
            ) : (
              <option value="screen">ã‚¿ãƒ–ã®éŸ³å£°ï¼ˆç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼‰</option>
            )}
          </select>
          
          {/* ãƒã‚¤ã‚¯æ¨©é™çŠ¶æ…‹è¡¨ç¤º */}
          {audioSource === 'microphone' && (
            <div className="flex items-center gap-2">
              {isCheckingPermission ? (
                <span className="text-sm text-gray-500">ãƒã‚§ãƒƒã‚¯ä¸­...</span>
              ) : (
                <div className={`flex items-center gap-1 text-sm px-2 py-1 rounded ${
                  micPermission === 'granted' ? 'bg-green-100 text-green-700' :
                  micPermission === 'denied' ? 'bg-red-100 text-red-700' :
                  'bg-yellow-100 text-yellow-700'
                }`}>
                  <span>
                    {micPermission === 'granted' ? 'âœ…' :
                     micPermission === 'denied' ? 'âŒ' : 'âš ï¸'}
                  </span>
                  <span>
                    {micPermission === 'granted' ? 'ãƒã‚¤ã‚¯è¨±å¯æ¸ˆã¿' :
                     micPermission === 'denied' ? 'ãƒã‚¤ã‚¯æ‹’å¦' :
                     'ãƒã‚¤ã‚¯æ¨©é™ä¸æ˜'}
                  </span>
                </div>
              )}
            </div>
          )}
        </div>

        {/* ãƒ–ãƒ©ã‚¦ã‚¶åˆ¥ã®è£œè¶³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
        {audioSource === 'screen' && (
          <div className="mt-2 text-xs text-gray-600 max-w-md mx-auto">
            {isSafari ? (
              <div className="rounded-md border border-yellow-200 bg-yellow-50 text-yellow-800 p-2">
                Safariã§ã¯ã‚¿ãƒ–/ç”»é¢å…±æœ‰ã«éŸ³å£°ãŒå«ã¾ã‚Œã¾ã›ã‚“ã€‚ã‚¿ãƒ–éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹å ´åˆã¯ Chrome/Edge ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚
              </div>
            ) : showScreenTip ? (
              <div className="rounded-md border border-blue-200 bg-blue-50 text-blue-800 p-2">
                ã‚¿ãƒ–éŸ³å£°ã‚’éŒ²éŸ³ã™ã‚‹ã«ã¯ã€å…±æœ‰ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã§ã€Œã‚¿ãƒ–ã€ã‚’é¸ã³ã€ŒéŸ³å£°ã‚’å…±æœ‰ã€ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã€éŸ³å£°ãŒå†ç”Ÿã•ã‚Œã¦ã„ã‚‹ã‚¿ãƒ–ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
              </div>
            ) : null}
          </div>
        )}

        {/* éŒ²éŸ³ãƒœã‚¿ãƒ³ */}
        <div className="flex flex-col items-center gap-4">
          {isRecording ? (
            <button
              onClick={handleStop}
              className="w-32 h-32 rounded-full bg-red-500 hover:bg-red-600 text-white font-bold text-xl transition-colors shadow-lg"
            >
              â–  åœæ­¢
            </button>
          ) : (
            <button
              onClick={handleStart}
              className="w-32 h-32 rounded-full bg-blue-500 hover:bg-blue-600 text-white font-bold text-xl transition-colors shadow-lg"
            >
              â— é–‹å§‹
            </button>
          )}
          
          {/* éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤º */}
          {isRecording && (
            <div className="flex flex-col items-center gap-2">
              <div className="w-64 h-4 bg-gray-200 rounded-full overflow-hidden">
                <div 
                  className="h-full bg-gradient-to-r from-green-400 via-yellow-400 to-red-500 transition-all duration-75"
                  style={{ width: `${audioLevel * 100}%` }}
                />
              </div>
              <span className="text-xs text-gray-600">éŸ³å£°ãƒ¬ãƒ™ãƒ«</span>
            </div>
          )}
        </div>

        <p className="text-sm text-gray-600">
          {isRecording 
            ? `${getSourceLabel()}ã‹ã‚‰éŒ²éŸ³ä¸­... è©±ã—çµ‚ã‚ã‚‹ã¨æ•°ç§’ã§æ–‡å­—ãŒå‡ºã¾ã™ã€‚`
            : `å…¥åŠ›ã‚½ãƒ¼ã‚¹: ${getSourceLabel()}`
          }
        </p>
      </div>

      {/* éŒ²éŸ³çµ±è¨ˆ */}
      {isRecording && wsStats.elapsed && (
        <div className="bg-gray-50 rounded-lg p-4">
          <div className="text-center text-sm text-gray-600">
            éŒ²éŸ³æ™‚é–“: {wsStats.elapsed}ç§’ | 
            ãƒ‡ãƒ¼ã‚¿: {Math.round((wsStats.bytes || 0) / 1024)}KB |
            {wsStats.idle ? ` ç„¡éŸ³: ${wsStats.idle}ç§’` : ''}
          </div>
        </div>
      )}

      {/* ãƒ©ã‚¤ãƒ–å­—å¹• */}
      <div className="bg-white rounded-xl border border-gray-200 p-6 min-h-64">
        <div className="flex items-center justify-between mb-4">
          <h2 className="text-lg font-semibold">ãƒ©ã‚¤ãƒ–å­—å¹•</h2>
          {transcripts.length > 0 && (
            <span className="text-sm text-gray-500">
              {transcripts.filter(t => t.type === 'final').length} ç™ºè©±
            </span>
          )}
        </div>
        
        {transcripts.length > 0 ? (
          <div className="space-y-3 max-h-96 overflow-y-auto">
            {transcripts.map((transcript) => (
              <div 
                key={transcript.id || transcript.text}
                className={`p-3 rounded-lg transition-all duration-200 ${
                  transcript.type === 'final' 
                    ? 'bg-green-50 border border-green-200' 
                    : 'bg-yellow-50 border border-yellow-200 animate-pulse'
                }`}
              >
                <div className="flex items-start gap-3">
                  <span className={`font-medium text-sm px-2 py-1 rounded ${
                    transcript.type === 'final' 
                      ? 'bg-green-100 text-green-700'
                      : 'bg-yellow-100 text-yellow-700'
                  }`}>
                    {transcript.speaker || 'S1'}
                  </span>
                  <div className="flex-1">
                    <p className="text-gray-900 leading-relaxed">{transcript.text}</p>
                    {transcript.mt && (
                      <p className="text-sm text-gray-600 mt-1 italic border-l-2 border-gray-300 pl-2">
                        {transcript.mt}
                      </p>
                    )}
                    {transcript.range && transcript.type === 'final' && (
                      <p className="text-xs text-gray-400 mt-1">
                        {transcript.range[0].toFixed(1)}s - {transcript.range[1].toFixed(1)}s
                      </p>
                    )}
                  </div>
                  <div className="flex items-center gap-2">
                    {transcript.type === 'partial' && (
                      <span className="text-xs text-yellow-600 font-medium">å‡¦ç†ä¸­...</span>
                    )}
                    {transcript.type === 'final' && (
                      <span className="text-xs text-green-600">âœ“</span>
                    )}
                  </div>
                </div>
              </div>
            ))}
            <div ref={transcriptsEndRef} />
          </div>
        ) : (
          <div className="text-center text-gray-500 py-8">
            {isRecording 
              ? 'è©±ã—ã¦ãã ã•ã„ã€‚éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã‚‹ã¨æ–‡å­—èµ·ã“ã—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚'
              : 'éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ãƒ©ã‚¤ãƒ–å­—å¹•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚'
            }
          </div>
        )}
      </div>

      {/* æ“ä½œã‚¬ã‚¤ãƒ‰ */}
      <div className="bg-blue-50 rounded-lg p-4">
        <h3 className="font-medium text-blue-900 mb-2">ä½¿ã„æ–¹</h3>
        <ul className="text-sm text-blue-800 space-y-1">
          <li>â€¢ å…¥åŠ›ã‚½ãƒ¼ã‚¹ã‚’é¸ã‚“ã§ã€Œé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„</li>
          <li>â€¢ è©±ã—çµ‚ã‚ã‚‹ã¨æ•°ç§’ã§æ–‡å­—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™</li>
          <li>â€¢ çµ‚ã‚ã£ãŸã‚‰ã€Œåœæ­¢ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚ä¿å­˜ã¯è‡ªå‹•ã§ã™</li>
          <li>â€¢ <strong>ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°å…¨ä½“ã‚’éŒ²éŸ³ï¼š</strong>BlackHoleç­‰ã®ä»®æƒ³éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ã‚·ã‚¹ãƒ†ãƒ å‡ºåŠ›ã‚’è¨­å®š</li>
          <li>â€¢ <strong>ç‰¹å®šã®ã‚¿ãƒ–éŸ³å£°ï¼š</strong>ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£ã§ã‚¿ãƒ–é¸æŠæ™‚ã«ã€ŒéŸ³å£°ã‚’å…±æœ‰ã€ã‚’ãƒã‚§ãƒƒã‚¯</li>
        </ul>
      </div>
    </div>
  )
}
